{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "589ee64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: no `access_key` or `secret_key` found for AWS, can only access public resources.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from typing import Dict\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "from rliable import library as rly\n",
    "from rliable import metrics\n",
    "\n",
    "from agent.evaluation import get_latest_checkpoint_filename\n",
    "from agent.evaluation import get_wandb_result_key\n",
    "from agent.random.evaluation import get_random_result_key\n",
    "from common.log_utils import logger\n",
    "from contrib.s3_utils import SimpleS3Client\n",
    "from datagen.world_creation.constants import TASKS_BY_TASK_GROUP\n",
    "from datagen.world_creation.constants import AvalonTaskGroup\n",
    "\n",
    "s3_client = SimpleS3Client()\n",
    "data_key = \"avalon_worlds__2f788115-ea32-4041-8cae-6e7cd33091b7.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c22ccf6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "## RANDOM BASELINE\n",
    "random_result_keys = [get_random_result_key(i, data_key) for i in range(10)]\n",
    "combined_random_results = defaultdict(list)\n",
    "for result_key in random_result_keys:\n",
    "    reported_data = json.loads(s3_client.load(result_key))\n",
    "    for k, v in reported_data[\"all_results\"].items():\n",
    "        combined_random_results[k].append(round(v, ndigits=3))\n",
    "\n",
    "random_agg_score = {}\n",
    "for k, v in combined_random_results.items():\n",
    "    random_agg_score[k] = np.mean(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbf66f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## HUMAN BASELINE\n",
    "human_scores_key = \"avalon__human_scores__935781fe-267d-4dcd-9698-714cc891e985.json\"\n",
    "\n",
    "human_scores = json.loads(s3_client.load(human_scores_key))\n",
    "human_agg_score = {}\n",
    "folder_name_lookup = {}\n",
    "for world_dir, human_results_on_world in human_scores.items():\n",
    "    k = str(int(world_dir.split(\"__\")[1]))\n",
    "    folder_name_lookup[k] = world_dir\n",
    "    human_agg_score[k] = np.mean(list(human_results_on_world.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5724931f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num levels 1000\n"
     ]
    }
   ],
   "source": [
    "valid_levels = set(human_agg_score.keys()) & set(random_agg_score.keys())\n",
    "\n",
    "human_fail_levels = set()\n",
    "for k in valid_levels:\n",
    "    if human_agg_score[k] <= random_agg_score[k]:\n",
    "        human_fail_levels.add(k)\n",
    "        fail_folder = folder_name_lookup[k]\n",
    "\n",
    "valid_levels -= human_fail_levels\n",
    "print(\"num levels\", len(valid_levels))\n",
    "\n",
    "\n",
    "def get_human_normalized_score(world_index: str, raw_score: float) -> float:\n",
    "    if world_index not in valid_levels:\n",
    "        logger.warning(f\"{world_index} not in valid_levels returning unnormalized score!\")\n",
    "        return raw_score\n",
    "    return max(0, raw_score - random_agg_score[world_index]) / (\n",
    "        human_agg_score[world_index] - random_agg_score[world_index]\n",
    "    )\n",
    "\n",
    "\n",
    "world_id_by_task = defaultdict(list)\n",
    "simple_tasks = set(x.value.lower() for x in TASKS_BY_TASK_GROUP[AvalonTaskGroup.SIMPLE])\n",
    "compositional_tasks = set(x.value.lower() for x in TASKS_BY_TASK_GROUP[AvalonTaskGroup.COMPOSITIONAL])\n",
    "for key in valid_levels:\n",
    "    task = folder_name_lookup[key].split(\"__\")[0]\n",
    "    world_id_by_task[task].append(key)\n",
    "    if task in simple_tasks:\n",
    "        world_id_by_task[\"simple\"].append(key)\n",
    "    if task in compositional_tasks:\n",
    "        world_id_by_task[\"compositional\"].append(key)\n",
    "    world_id_by_task[\"all\"].append(key)\n",
    "\n",
    "\n",
    "def task_dict_to_score_numpys(task_dict: Dict[str, List[float]]):\n",
    "    np_task_dict: Dict[str, np.ndarray] = {}\n",
    "    for task, keys in world_id_by_task.items():\n",
    "        np_task_dict[task] = np.stack([np.array(task_dict[k]) for k in keys])\n",
    "    return np_task_dict\n",
    "\n",
    "\n",
    "PRINT_TASK_ORDER = [x.value.lower() for x in TASKS_BY_TASK_GROUP[AvalonTaskGroup.ALL]] + [\n",
    "    \"simple\",\n",
    "    \"compositional\",\n",
    "    \"all\",\n",
    "]\n",
    "\n",
    "\n",
    "aggregate_func = lambda x: np.array(\n",
    "    [\n",
    "        metrics.aggregate_mean(x),\n",
    "        metrics.aggregate_optimality_gap(x),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def print_aggregate_results(score_numpys: Dict[str, np.ndarray]):\n",
    "    aggregate_scores, aggregate_score_cis = rly.get_interval_estimates(score_numpys, aggregate_func, reps=1000)\n",
    "    for task in PRINT_TASK_ORDER:\n",
    "        mean, opt_gap = aggregate_scores[task]\n",
    "        mean_low, mean_high = aggregate_score_cis[task][:, 0]\n",
    "        mean_sig = (mean_high - mean_low) / 2\n",
    "        opt_gap_low, opt_gap_high = aggregate_score_cis[task][:, 1]\n",
    "        opt_gap_sig = (mean_high - mean_low) / 2\n",
    "        print(f\"{task.upper()}: mean {mean:.3f} +- {mean_sig:.3f}, og: {opt_gap:.3f} +- {opt_gap_sig:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8fffa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading results for model_step_50006400.tar from sourceress/abe__torchbeast/15670wcf\n",
      "Loading results for model_step_50006400.tar from sourceress/abe__torchbeast/w0zt8c1r\n",
      "Loading results for model_step_50003200.tar from sourceress/abe__torchbeast/320exk7d\n",
      "Loading results for model_step_50000000.tar from sourceress/abe__torchbeast/20j4n9dd\n",
      "Loading results for model_step_50006400.tar from sourceress/abe__torchbeast/zq1hs2h3\n",
      "Loading results for model_step_50003200.tar from sourceress/abe__torchbeast/3szvt5xc\n",
      "Loading results for model_step_50003200.tar from sourceress/abe__torchbeast/so13nk61\n",
      "Loading results for model_step_50003200.tar from sourceress/abe__torchbeast/38z8lhh9\n",
      "\n",
      "Torchbeast 50m aggregated scores\n",
      "EAT: mean 0.617 +- 0.050, og: 0.429 +- 0.050\n",
      "MOVE: mean 0.398 +- 0.049, og: 0.621 +- 0.049\n",
      "JUMP: mean 0.327 +- 0.050, og: 0.697 +- 0.050\n",
      "CLIMB: mean 0.268 +- 0.042, og: 0.739 +- 0.042\n",
      "DESCEND: mean 0.614 +- 0.055, og: 0.463 +- 0.055\n",
      "SCRAMBLE: mean 0.437 +- 0.049, og: 0.586 +- 0.049\n",
      "STACK: mean 0.212 +- 0.030, og: 0.788 +- 0.030\n",
      "BRIDGE: mean 0.027 +- 0.016, og: 0.973 +- 0.016\n",
      "PUSH: mean 0.214 +- 0.040, og: 0.798 +- 0.040\n",
      "THROW: mean 0.004 +- 0.006, og: 0.996 +- 0.006\n",
      "HUNT: mean 0.075 +- 0.026, og: 0.928 +- 0.026\n",
      "FIGHT: mean 0.356 +- 0.060, og: 0.727 +- 0.060\n",
      "AVOID: mean 0.664 +- 0.050, og: 0.392 +- 0.050\n",
      "EXPLORE: mean 0.150 +- 0.025, og: 0.850 +- 0.025\n",
      "OPEN: mean 0.639 +- 0.048, og: 0.416 +- 0.048\n",
      "CARRY: mean 0.079 +- 0.020, og: 0.921 +- 0.020\n",
      "NAVIGATE: mean 0.013 +- 0.007, og: 0.987 +- 0.007\n",
      "FIND: mean 0.003 +- 0.003, og: 0.997 +- 0.003\n",
      "SURVIVE: mean 0.040 +- 0.010, og: 0.960 +- 0.010\n",
      "GATHER: mean 0.011 +- 0.006, og: 0.989 +- 0.006\n",
      "SIMPLE: mean 0.318 +- 0.012, og: 0.708 +- 0.012\n",
      "COMPOSITIONAL: mean 0.017 +- 0.004, og: 0.983 +- 0.004\n",
      "ALL: mean 0.257 +- 0.010, og: 0.763 +- 0.010\n"
     ]
    }
   ],
   "source": [
    "WANDB_API_KEY=4be396c91a1edc3dc88d28749bb9d146dfc0afb8\n",
    "## TORCHBEAST BASELINE\n",
    "wandb_runs = [\n",
    "    \"sourceress/abe__torchbeast/15670wcf\",\n",
    "    \"sourceress/abe__torchbeast/w0zt8c1r\",\n",
    "    \"sourceress/abe__torchbeast/320exk7d\",\n",
    "    \"sourceress/abe__torchbeast/20j4n9dd\",\n",
    "    \"sourceress/abe__torchbeast/zq1hs2h3\",\n",
    "    \"sourceress/abe__torchbeast/3szvt5xc\",\n",
    "    \"sourceress/abe__torchbeast/so13nk61\",\n",
    "    \"sourceress/abe__torchbeast/38z8lhh9\",\n",
    "]\n",
    "combined_torchbeast_results = defaultdict(list)\n",
    "raw_torchbeast_datas = []\n",
    "for wandb_run in wandb_runs:\n",
    "    checkpoint_filename = get_latest_checkpoint_filename(wandb_run, prefix=\"model_step_\", suffix=\".tar\")\n",
    "    logger.info(f\"Loading results for {checkpoint_filename} from {wandb_run}\")\n",
    "    result_key = get_wandb_result_key(wandb_run, checkpoint_filename, data_key)\n",
    "    reported_data = json.loads(s3_client.load(result_key))\n",
    "    raw_torchbeast_datas.append(reported_data)\n",
    "    missing_levels = valid_levels - set(reported_data[\"all_results\"].keys())\n",
    "    if len(missing_levels) > 0:\n",
    "        logger.warning(f\"{wandb_run} is missing {len(missing_levels)} levels, ignoring incomplete data\")\n",
    "    else:\n",
    "        for k in valid_levels:\n",
    "            level_data = reported_data[\"all_results\"][k]\n",
    "            combined_torchbeast_results[k].append(get_human_normalized_score(k, level_data))\n",
    "\n",
    "torchbeast_score_numpys = task_dict_to_score_numpys(combined_torchbeast_results)\n",
    "\n",
    "print(\"\\nTorchbeast 50m aggregated scores\")\n",
    "print_aggregate_results(torchbeast_score_numpys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ecb6e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading results for model_29860800.pt from sourceress/abe__ppo/3jjf1kmx\n",
      "Loading results for model_29860800.pt from sourceress/abe__ppo/3laawj88\n",
      "Loading results for model_29860800.pt from sourceress/abe__ppo/2a4vx29a\n",
      "Loading results for model_29860800.pt from sourceress/abe__ppo/2iivkxvy\n",
      "Loading results for model_29860800.pt from sourceress/abe__ppo/2w50d2g3\n",
      "Loading results for model_29860800.pt from sourceress/abe__ppo/1v9ega3f\n",
      "\n",
      "PPO 30m aggregated scores\n",
      "EAT: mean 0.561 +- 0.068, og: 0.541 +- 0.068\n",
      "MOVE: mean 0.229 +- 0.052, og: 0.797 +- 0.052\n",
      "JUMP: mean 0.153 +- 0.045, og: 0.870 +- 0.045\n",
      "CLIMB: mean 0.117 +- 0.039, og: 0.895 +- 0.039\n",
      "DESCEND: mean 0.188 +- 0.049, og: 0.848 +- 0.049\n",
      "SCRAMBLE: mean 0.245 +- 0.050, og: 0.802 +- 0.050\n",
      "STACK: mean 0.095 +- 0.028, og: 0.906 +- 0.028\n",
      "BRIDGE: mean 0.000 +- 0.000, og: 1.000 +- 0.000\n",
      "PUSH: mean 0.074 +- 0.030, og: 0.935 +- 0.030\n",
      "THROW: mean 0.000 +- 0.000, og: 1.000 +- 0.000\n",
      "HUNT: mean 0.025 +- 0.016, og: 0.976 +- 0.016\n",
      "FIGHT: mean 0.073 +- 0.040, og: 0.952 +- 0.040\n",
      "AVOID: mean 0.162 +- 0.039, og: 0.860 +- 0.039\n",
      "EXPLORE: mean 0.108 +- 0.029, og: 0.893 +- 0.029\n",
      "OPEN: mean 0.277 +- 0.048, og: 0.748 +- 0.048\n",
      "CARRY: mean 0.020 +- 0.014, og: 0.980 +- 0.014\n",
      "NAVIGATE: mean 0.000 +- 0.000, og: 1.000 +- 0.000\n",
      "FIND: mean 0.002 +- 0.004, og: 0.998 +- 0.004\n",
      "SURVIVE: mean 0.020 +- 0.006, og: 0.980 +- 0.006\n",
      "GATHER: mean 0.004 +- 0.004, og: 0.996 +- 0.004\n",
      "SIMPLE: mean 0.145 +- 0.011, og: 0.875 +- 0.011\n",
      "COMPOSITIONAL: mean 0.007 +- 0.002, og: 0.993 +- 0.002\n",
      "ALL: mean 0.118 +- 0.009, og: 0.899 +- 0.009\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## PPO BASELINE\n",
    "wandb_runs = [\n",
    "    \"sourceress/abe__ppo/3jjf1kmx\",\n",
    "    \"sourceress/abe__ppo/3laawj88\",\n",
    "    \"sourceress/abe__ppo/2a4vx29a\",\n",
    "    \"sourceress/abe__ppo/2iivkxvy\",\n",
    "    \"sourceress/abe__ppo/2w50d2g3\",\n",
    "    \"sourceress/abe__ppo/1v9ega3f\",\n",
    "]\n",
    "checkpoint_filename = \"model_29860800.pt\"\n",
    "combined_ppo_results = defaultdict(list)\n",
    "raw_ppo_datas = []\n",
    "for wandb_run in wandb_runs:\n",
    "    logger.info(f\"Loading results for {checkpoint_filename} from {wandb_run}\")\n",
    "    result_key = get_wandb_result_key(wandb_run, checkpoint_filename, data_key)\n",
    "    reported_data = json.loads(s3_client.load(result_key))\n",
    "    raw_ppo_datas.append(reported_data)\n",
    "    missing_levels = valid_levels - set(reported_data[\"all_results\"].keys())\n",
    "    if len(missing_levels) > 0:\n",
    "        logger.warning(f\"{wandb_run} is missing {len(missing_levels)} levels, ignoring incomplete data\")\n",
    "    else:\n",
    "        for k in valid_levels:\n",
    "            level_data = reported_data[\"all_results\"][k]\n",
    "            combined_ppo_results[k].append(get_human_normalized_score(k, level_data))\n",
    "\n",
    "\n",
    "ppo_score_numpys = task_dict_to_score_numpys(combined_ppo_results)\n",
    "print(\"\\nPPO 30m aggregated scores\")\n",
    "print_aggregate_results(ppo_score_numpys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59736379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Curriculum ablation aggregated scores\n",
      "\n",
      "Curriculum: Task only\n",
      "EAT: mean 0.495 +- 0.078, og: 0.528 +- 0.078\n",
      "MOVE: mean 0.428 +- 0.082, og: 0.588 +- 0.082\n",
      "JUMP: mean 0.283 +- 0.074, og: 0.735 +- 0.074\n",
      "CLIMB: mean 0.231 +- 0.063, og: 0.773 +- 0.063\n",
      "DESCEND: mean 0.737 +- 0.093, og: 0.351 +- 0.093\n",
      "SCRAMBLE: mean 0.413 +- 0.081, og: 0.606 +- 0.081\n",
      "STACK: mean 0.322 +- 0.059, og: 0.680 +- 0.059\n",
      "BRIDGE: mean 0.013 +- 0.016, og: 0.987 +- 0.016\n",
      "PUSH: mean 0.233 +- 0.072, og: 0.784 +- 0.072\n",
      "THROW: mean 0.000 +- 0.000, og: 1.000 +- 0.000\n",
      "HUNT: mean 0.057 +- 0.033, og: 0.944 +- 0.033\n",
      "FIGHT: mean 0.417 +- 0.104, og: 0.683 +- 0.104\n",
      "AVOID: mean 0.752 +- 0.091, og: 0.332 +- 0.091\n",
      "EXPLORE: mean 0.156 +- 0.045, og: 0.844 +- 0.045\n",
      "OPEN: mean 0.681 +- 0.073, og: 0.365 +- 0.073\n",
      "CARRY: mean 0.122 +- 0.043, og: 0.881 +- 0.043\n",
      "NAVIGATE: mean 0.005 +- 0.006, og: 0.995 +- 0.006\n",
      "FIND: mean 0.015 +- 0.013, og: 0.985 +- 0.013\n",
      "SURVIVE: mean 0.029 +- 0.011, og: 0.971 +- 0.011\n",
      "GATHER: mean 0.016 +- 0.011, og: 0.984 +- 0.011\n",
      "SIMPLE: mean 0.334 +- 0.019, og: 0.693 +- 0.019\n",
      "COMPOSITIONAL: mean 0.016 +- 0.005, og: 0.984 +- 0.005\n",
      "ALL: mean 0.270 +- 0.016, og: 0.751 +- 0.016\n",
      "\n",
      "Curriculum: Meta only\n",
      "EAT: mean 0.619 +- 0.080, og: 0.415 +- 0.080\n",
      "MOVE: mean 0.377 +- 0.081, og: 0.657 +- 0.081\n",
      "JUMP: mean 0.204 +- 0.065, og: 0.808 +- 0.065\n",
      "CLIMB: mean 0.120 +- 0.050, og: 0.884 +- 0.050\n",
      "DESCEND: mean 0.479 +- 0.090, og: 0.588 +- 0.090\n",
      "SCRAMBLE: mean 0.130 +- 0.057, og: 0.878 +- 0.057\n",
      "STACK: mean 0.204 +- 0.050, og: 0.797 +- 0.050\n",
      "BRIDGE: mean 0.014 +- 0.017, og: 0.987 +- 0.017\n",
      "PUSH: mean 0.094 +- 0.041, og: 0.909 +- 0.041\n",
      "THROW: mean 0.000 +- 0.000, og: 1.000 +- 0.000\n",
      "HUNT: mean 0.029 +- 0.025, og: 0.971 +- 0.025\n",
      "FIGHT: mean 0.240 +- 0.082, og: 0.810 +- 0.082\n",
      "AVOID: mean 0.317 +- 0.076, og: 0.708 +- 0.076\n",
      "EXPLORE: mean 0.104 +- 0.038, og: 0.897 +- 0.038\n",
      "OPEN: mean 0.481 +- 0.074, og: 0.544 +- 0.074\n",
      "CARRY: mean 0.083 +- 0.038, og: 0.919 +- 0.038\n",
      "NAVIGATE: mean 0.000 +- 0.000, og: 1.000 +- 0.000\n",
      "FIND: mean 0.004 +- 0.005, og: 0.996 +- 0.005\n",
      "SURVIVE: mean 0.037 +- 0.019, og: 0.964 +- 0.019\n",
      "GATHER: mean 0.002 +- 0.003, og: 0.998 +- 0.003\n",
      "SIMPLE: mean 0.218 +- 0.017, og: 0.798 +- 0.017\n",
      "COMPOSITIONAL: mean 0.011 +- 0.005, og: 0.989 +- 0.005\n",
      "ALL: mean 0.177 +- 0.014, og: 0.836 +- 0.014\n",
      "\n",
      "Curriculum: None\n",
      "EAT: mean 0.079 +- 0.040, og: 0.921 +- 0.040\n",
      "MOVE: mean 0.018 +- 0.019, og: 0.982 +- 0.019\n",
      "JUMP: mean 0.006 +- 0.011, og: 0.994 +- 0.011\n",
      "CLIMB: mean 0.000 +- 0.000, og: 1.000 +- 0.000\n",
      "DESCEND: mean 0.024 +- 0.022, og: 0.976 +- 0.022\n",
      "SCRAMBLE: mean 0.006 +- 0.009, og: 0.994 +- 0.009\n",
      "STACK: mean 0.000 +- 0.000, og: 1.000 +- 0.000\n",
      "BRIDGE: mean 0.000 +- 0.000, og: 1.000 +- 0.000\n",
      "PUSH: mean 0.004 +- 0.005, og: 0.996 +- 0.005\n",
      "THROW: mean 0.000 +- 0.000, og: 1.000 +- 0.000\n",
      "HUNT: mean 0.010 +- 0.012, og: 0.990 +- 0.012\n",
      "FIGHT: mean 0.000 +- 0.000, og: 1.000 +- 0.000\n",
      "AVOID: mean 0.000 +- 0.000, og: 1.000 +- 0.000\n",
      "EXPLORE: mean 0.020 +- 0.016, og: 0.980 +- 0.016\n",
      "OPEN: mean 0.088 +- 0.037, og: 0.912 +- 0.037\n",
      "CARRY: mean 0.000 +- 0.000, og: 1.000 +- 0.000\n",
      "NAVIGATE: mean 0.000 +- 0.000, og: 1.000 +- 0.000\n",
      "FIND: mean 0.000 +- 0.000, og: 1.000 +- 0.000\n",
      "SURVIVE: mean 0.002 +- 0.002, og: 0.998 +- 0.002\n",
      "GATHER: mean 0.000 +- 0.000, og: 1.000 +- 0.000\n",
      "SIMPLE: mean 0.016 +- 0.004, og: 0.984 +- 0.004\n",
      "COMPOSITIONAL: mean 0.001 +- 0.001, og: 0.999 +- 0.001\n",
      "ALL: mean 0.013 +- 0.004, og: 0.987 +- 0.004\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## TORCHBEAST CURRICULUM ABLATION\n",
    "result_keys_by_curriculum = {\n",
    "    \"task_only\": [\n",
    "        \"sourceress_abe__torchbeast_1viushv8__model_step_39388800.tar__avalon_worlds__2f788115-ea32-4041-8cae-6e7cd33091b7.tar.gz\",\n",
    "        \"sourceress_abe__torchbeast_148f6z8f__model_step_43606400.tar__avalon_worlds__2f788115-ea32-4041-8cae-6e7cd33091b7.tar.gz\",\n",
    "        \"sourceress_abe__torchbeast_t68l25tc__model_step_43913600.tar__avalon_worlds__2f788115-ea32-4041-8cae-6e7cd33091b7.tar.gz\",\n",
    "    ],\n",
    "    \"none\": [\n",
    "        \"sourceress_abe__torchbeast_31n7esqp__model_step_20633600.tar__avalon_worlds__2f788115-ea32-4041-8cae-6e7cd33091b7.tar.gz\",\n",
    "        \"sourceress_abe__torchbeast_1hnfpgr3__model_step_22275200.tar__avalon_worlds__2f788115-ea32-4041-8cae-6e7cd33091b7.tar.gz\",\n",
    "        \"sourceress_abe__torchbeast_1bijqylb__model_step_16748800.tar__avalon_worlds__2f788115-ea32-4041-8cae-6e7cd33091b7.tar.gz\",\n",
    "    ],\n",
    "    \"meta_only\": [\n",
    "        \"sourceress_abe__torchbeast_30l8m6t9__model_step_37008000.tar__avalon_worlds__2f788115-ea32-4041-8cae-6e7cd33091b7.tar.gz\",\n",
    "        \"sourceress_abe__torchbeast_2sw328jm__model_step_37187200.tar__avalon_worlds__2f788115-ea32-4041-8cae-6e7cd33091b7.tar.gz\",\n",
    "        \"sourceress_abe__torchbeast_rattuz9h__model_step_37552000.tar__avalon_worlds__2f788115-ea32-4041-8cae-6e7cd33091b7.tar.gz\",\n",
    "    ],\n",
    "}\n",
    "torchbeast_curriculum_results = {\n",
    "    \"task_only\": defaultdict(list),\n",
    "    \"meta_only\": defaultdict(list),\n",
    "    \"none\": defaultdict(list),\n",
    "}\n",
    "for curriculum, result_keys in result_keys_by_curriculum.items():\n",
    "    for result_key in result_keys:\n",
    "        reported_data = json.loads(s3_client.load(result_key))\n",
    "        missing_levels = valid_levels - set(reported_data[\"all_results\"].keys())\n",
    "        if len(missing_levels) > 0:\n",
    "            logger.warning(f\"{result_key} is missing {len(missing_levels)} levels, ignoring incomplete data\")\n",
    "        else:\n",
    "            for k in valid_levels:\n",
    "                level_data = reported_data[\"all_results\"][k]\n",
    "                torchbeast_curriculum_results[curriculum][k].append(get_human_normalized_score(k, level_data))\n",
    "\n",
    "\n",
    "curriculum_score_numpys = {k: task_dict_to_score_numpys(v) for k, v in torchbeast_curriculum_results.items()}\n",
    "print(\"\\nCurriculum ablation aggregated scores\")\n",
    "for curriculum, scores in curriculum_score_numpys.items():\n",
    "    print(f'\\nCurriculum: {curriculum.replace(\"_\", \" \").capitalize()}')\n",
    "    print_aggregate_results(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf63a4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
