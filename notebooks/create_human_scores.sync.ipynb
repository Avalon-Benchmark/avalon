{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": ""
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import shutil\n",
    "import tarfile\n",
    "from collections import OrderedDict\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Pool\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "from typing import List\n",
    "from typing import NamedTuple\n",
    "\n",
    "from avalon.common.imports import tqdm\n",
    "from avalon.common.log_utils import enable_debug_logging\n",
    "from avalon.common.log_utils import logger\n",
    "from avalon.contrib.s3_utils import SimpleS3Client\n",
    "from avalon.contrib.utils import FILESYSTEM_ROOT\n",
    "from avalon.datagen.env_helper import create_env\n",
    "from avalon.datagen.env_helper import get_action_type_from_config\n",
    "from avalon.datagen.godot_env.goals import GoalProgressResult\n",
    "from avalon.datagen.godot_env.goals import AvalonGoalEvaluator\n",
    "from avalon.datagen.godot_env.observations import AvalonObservation\n",
    "from avalon.datagen.human_playback import get_observations_from_human_recording\n",
    "from avalon.datagen.human_playback import get_oculus_playback_config\n",
    "from avalon.datagen.world_creation.constants import AvalonTask\n",
    "from avalon.datagen.world_creation.world_generator import GenerateAvalonWorldParams\n",
    "\n",
    "enable_debug_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ScoreResult(NamedTuple):\n",
    "    world_id: str\n",
    "    user_id: str\n",
    "    score: float\n",
    "    is_error: bool\n",
    "    is_reset: bool\n",
    "\n",
    "\n",
    "class HumanScores(NamedTuple):\n",
    "    score_by_world_id: Dict[str, Dict[str, float]]\n",
    "    resets_by_user_id: Dict[str, List[str]]\n",
    "    uncaught_errors: List[BaseException]\n",
    "    expected_errors: List[ScoreResult]\n",
    "\n",
    "\n",
    "class InvalidEpisode(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class PathDoesNotExit(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "class UnexpectedPath(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "VALID_APK_VERSIONS = [\n",
    "    \"6a88384c83e5a103cb2a10d4561315297d5019d2\",\n",
    "    \"974025deded7ebe9c39d95d472048ec267d6caad\",\n",
    "    \"d217981d161e790ac702b46ecfa8286bea153d54\",\n",
    "    \"df9b06e74922efb57bc582931588d08e015f5036\",\n",
    "]\n",
    "\n",
    "\n",
    "def get_human_score(\n",
    "    world_params: GenerateAvalonWorldParams, observations: List[AvalonObservation]\n",
    ") -> GoalProgressResult:\n",
    "    goal_evaluator = AvalonGoalEvaluator()\n",
    "    goal_evaluator.reset(observations[0], world_params)\n",
    "    for obs in observations[1:]:\n",
    "        progress = goal_evaluator.calculate_goal_progress(obs)\n",
    "        if progress.is_done:\n",
    "            return progress\n",
    "\n",
    "    raise InvalidEpisode(\"is_done flag never set to True\")\n",
    "\n",
    "\n",
    "def _read_gzip_path_if_path_does_not_exist(path: Path) -> Path:\n",
    "    gzip_path = Path(f\"{path}.gz\")\n",
    "    if gzip_path.exists() and not path.exists():\n",
    "        with gzip.open(str(gzip_path), \"rb\") as f_in:\n",
    "            with open(path, \"wb\") as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "    return path\n",
    "\n",
    "\n",
    "def get_human_score_from_data(\n",
    "    user_path: Path, world_id: str, user_id: str, selected_features: OrderedDict\n",
    ") -> ScoreResult:\n",
    "    task, seed, difficulty = world_id.split(\"__\")\n",
    "\n",
    "    is_reset = (user_path / \"reset.marker\").exists()\n",
    "\n",
    "    if is_reset:\n",
    "        return ScoreResult(\n",
    "            world_id=world_id,\n",
    "            user_id=user_id,\n",
    "            score=0.0,\n",
    "            is_error=False,\n",
    "            is_reset=True,\n",
    "        )\n",
    "    user_path_with_apk_versions = [user_path / x for x in VALID_APK_VERSIONS if (user_path / x).exists()]\n",
    "    if len(user_path_with_apk_versions) > 1:\n",
    "        raise UnexpectedPath(f\"Found multiple paths {user_path_with_apk_versions}\")\n",
    "\n",
    "    if len(user_path_with_apk_versions) == 0:\n",
    "        logger.error(\n",
    "            f\"No sub-path in {user_path} that matches {VALID_APK_VERSIONS}. Either run just started or something went wrong.\"\n",
    "        )\n",
    "        return ScoreResult(world_id=world_id, user_id=user_id, score=0.0, is_error=True, is_reset=False)\n",
    "\n",
    "    user_path_with_apk_version = user_path_with_apk_versions[0]\n",
    "\n",
    "    observations_path = _read_gzip_path_if_path_does_not_exist(user_path_with_apk_version / \"observations.out\")\n",
    "    if not observations_path.exists():\n",
    "        raise PathDoesNotExit(str(observations_path))\n",
    "\n",
    "    human_observations = get_observations_from_human_recording(\n",
    "        observations_path=observations_path,\n",
    "        selected_features=selected_features,\n",
    "    )\n",
    "\n",
    "    world_params = GenerateAvalonWorldParams(\n",
    "        task=AvalonTask[task.upper()], difficulty=float(difficulty), seed=int(seed), index=0, output=\"\"\n",
    "    )\n",
    "    try:\n",
    "        progress = get_human_score(world_params, human_observations)\n",
    "    except InvalidEpisode as e:\n",
    "        logger.error(e)\n",
    "        return ScoreResult(world_id=world_id, user_id=user_id, score=0.0, is_error=True, is_reset=False)\n",
    "\n",
    "    return ScoreResult(\n",
    "        world_id=world_id,\n",
    "        user_id=user_id,\n",
    "        score=progress.log[\"score\"],\n",
    "        is_error=False,\n",
    "        is_reset=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_all_human_scores(root_path: Path) -> HumanScores:\n",
    "    score_by_world_id: Dict[str, Dict[str, float]] = defaultdict(dict)\n",
    "    resets_by_user_id: Dict[str, List[str]] = defaultdict(list)\n",
    "    uncaught_errors: List[BaseException] = []\n",
    "    expected_errors: List[ScoreResult] = []\n",
    "\n",
    "    def on_done(result: ScoreResult):\n",
    "        if result.is_error:\n",
    "            expected_errors.append(result)\n",
    "        elif result.is_reset:\n",
    "            resets_by_user_id[result.user_id].append(result.world_id)\n",
    "        else:\n",
    "            score_by_world_id[result.world_id][result.user_id] = result.score\n",
    "\n",
    "    def on_error(error: BaseException):\n",
    "        logger.error(\"Evaluation failed!\")\n",
    "        uncaught_errors.append(error)\n",
    "        raise error\n",
    "\n",
    "    num_processes = 20\n",
    "\n",
    "    pool_results = []\n",
    "\n",
    "    config = get_oculus_playback_config(is_using_human_input=False)\n",
    "    action_type = get_action_type_from_config(config)\n",
    "    env = create_env(config, action_type)\n",
    "    selected_features = env.observation_context.selected_features\n",
    "    env.close()\n",
    "\n",
    "    with Pool(processes=num_processes) as worker_pool:\n",
    "        requests = []\n",
    "        for world_path in list(root_path.iterdir()):\n",
    "            world_id = world_path.name\n",
    "            if (\n",
    "                (world_path / \"ignored.marker\").exists()\n",
    "                or world_id.startswith(\"practice\")\n",
    "                or world_id.startswith(\"worlds\")\n",
    "                or world_id.startswith(\"versions\")\n",
    "            ):\n",
    "                continue\n",
    "            for user_path in world_path.iterdir():\n",
    "                user_id = user_path.name\n",
    "                if (user_path / \"crash\").exists():\n",
    "                    continue\n",
    "\n",
    "                task_name, seed, difficulty = world_id.split(\"__\")\n",
    "                cleaned_world_id = f\"{task_name}__{int(seed)}__{difficulty}\"\n",
    "\n",
    "                request = worker_pool.apply_async(\n",
    "                    get_human_score_from_data,\n",
    "                    kwds={\n",
    "                        \"user_path\": user_path,\n",
    "                        \"world_id\": cleaned_world_id,\n",
    "                        \"user_id\": user_id,\n",
    "                        \"selected_features\": selected_features,\n",
    "                    },\n",
    "                    callback=on_done,\n",
    "                    error_callback=on_error,\n",
    "                )\n",
    "                requests.append(request)\n",
    "        for request in tqdm(requests):\n",
    "            request.wait()\n",
    "            if request._success:\n",
    "                pool_results.append(request.get())\n",
    "        worker_pool.close()\n",
    "        worker_pool.join()\n",
    "\n",
    "    return HumanScores(\n",
    "        score_by_world_id,\n",
    "        resets_by_user_id,\n",
    "        uncaught_errors,\n",
    "        expected_errors,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NotebookKernel processing request:\n",
      "\t\t{\"jsonrpc\": \"2.0\", \"method\": \"SyncRequest\", \"params\": {\"data\": {\"file_name\": \"/home/maksis/hub/testgrounds/generally_intelligent/standalone/avalon/notebooks/create_human_scores.sync.py\", \"contents\": \"# %%\\nimport gzip\\nimport json\\nimport shutil\\nimport tarfile\\nfrom collections import OrderedDict\\nfrom collections import defaultdict\\nfrom multiprocessing import Pool\\nfrom pathlib import Path\\nfrom typing import Dict\\nfrom typing import List\\nfrom typing import NamedTuple\\n\\nfrom avalon.common.imports import tqdm\\nfrom avalon.common.log_utils import enable_debug_logging\\nfrom avalon.common.log_utils import logger\\nfrom avalon.contrib.s3_utils import SimpleS3Client\\nfrom avalon.contrib.utils import FILESYSTEM_ROOT\\nfrom avalon.datagen.env_helper import create_env\\nfrom avalon.datagen.env_helper import get_action_type_from_config\\nfrom avalon.datagen.godot_env.goals import GoalProgressResult\\nfrom avalon.datagen.godot_env.goals import AvalonGoalEvaluator\\nfrom avalon.datagen.godot_env.observations import AvalonObservation\\nfrom avalon.datagen.human_playback import get_observations_from_human_recording\\nfrom avalon.datagen.human_playback import get_oculus_playback_config\\nfrom avalon.datagen.world_creation.constants import AvalonTask\\nfrom avalon.datagen.world_creation.world_generator import GenerateAvalonWorldParams\\n\\nenable_debug_logging()\\n\\n# %%\\n\\n\\nclass ScoreResult(NamedTuple):\\n    world_id: str\\n    user_id: str\\n    score: float\\n    is_error: bool\\n    is_reset: bool\\n\\n\\nclass HumanScores(NamedTuple):\\n    score_by_world_id: Dict[str, Dict[str, float]]\\n    resets_by_user_id: Dict[str, List[str]]\\n    uncaught_errors: List[BaseException]\\n    expected_errors: List[ScoreResult]\\n\\n\\nclass InvalidEpisode(Exception):\\n    pass\\n\\n\\nclass PathDoesNotExit(Exception):\\n    pass\\n\\n\\nclass UnexpectedPath(Exception):\\n    pass\\n\\n\\nVALID_APK_VERSIONS = [\\n    \\\"6a88384c83e5a103cb2a10d4561315297d5019d2\\\",\\n    \\\"974025deded7ebe9c39d95d472048ec267d6caad\\\",\\n    \\\"d217981d161e790ac702b46ecfa8286bea153d54\\\",\\n    \\\"df9b06e74922efb57bc582931588d08e015f5036\\\",\\n]\\n\\n\\ndef get_human_score(\\n    world_params: GenerateAvalonWorldParams, observations: List[AvalonObservation]\\n) -> GoalProgressResult:\\n    goal_evaluator = AvalonGoalEvaluator()\\n    goal_evaluator.reset(observations[0], world_params)\\n    for obs in observations[1:]:\\n        progress = goal_evaluator.calculate_goal_progress(obs)\\n        if progress.is_done:\\n            return progress\\n\\n    raise InvalidEpisode(\\\"is_done flag never set to True\\\")\\n\\n\\ndef _read_gzip_path_if_path_does_not_exist(path: Path) -> Path:\\n    gzip_path = Path(f\\\"{path}.gz\\\")\\n    if gzip_path.exists() and not path.exists():\\n        with gzip.open(str(gzip_path), \\\"rb\\\") as f_in:\\n            with open(path, \\\"wb\\\") as f_out:\\n                shutil.copyfileobj(f_in, f_out)\\n    return path\\n\\n\\ndef get_human_score_from_data(\\n    user_path: Path, world_id: str, user_id: str, selected_features: OrderedDict\\n) -> ScoreResult:\\n    task, seed, difficulty = world_id.split(\\\"__\\\")\\n\\n    is_reset = (user_path / \\\"reset.marker\\\").exists()\\n\\n    if is_reset:\\n        return ScoreResult(\\n            world_id=world_id,\\n            user_id=user_id,\\n            score=0.0,\\n            is_error=False,\\n            is_reset=True,\\n        )\\n    user_path_with_apk_versions = [user_path / x for x in VALID_APK_VERSIONS if (user_path / x).exists()]\\n    if len(user_path_with_apk_versions) > 1:\\n        raise UnexpectedPath(f\\\"Found multiple paths {user_path_with_apk_versions}\\\")\\n\\n    if len(user_path_with_apk_versions) == 0:\\n        logger.error(\\n            f\\\"No sub-path in {user_path} that matches {VALID_APK_VERSIONS}. Either run just started or something went wrong.\\\"\\n        )\\n        return ScoreResult(world_id=world_id, user_id=user_id, score=0.0, is_error=True, is_reset=False)\\n\\n    user_path_with_apk_version = user_path_with_apk_versions[0]\\n\\n    observations_path = _read_gzip_path_if_path_does_not_exist(user_path_with_apk_version / \\\"observations.out\\\")\\n    if not observations_path.exists():\\n        raise PathDoesNotExit(str(observations_path))\\n\\n    human_observations = get_observations_from_human_recording(\\n        observations_path=observations_path,\\n        selected_features=selected_features,\\n    )\\n\\n    world_params = GenerateAvalonWorldParams(\\n        task=AvalonTask[task.upper()], difficulty=float(difficulty), seed=int(seed), index=0, output=\\\"\\\"\\n    )\\n    try:\\n        progress = get_human_score(world_params, human_observations)\\n    except InvalidEpisode as e:\\n        logger.error(e)\\n        return ScoreResult(world_id=world_id, user_id=user_id, score=0.0, is_error=True, is_reset=False)\\n\\n    return ScoreResult(\\n        world_id=world_id,\\n        user_id=user_id,\\n        score=progress.log[\\\"score\\\"],\\n        is_error=False,\\n        is_reset=False,\\n    )\\n\\n\\ndef get_all_human_scores(root_path: Path) -> HumanScores:\\n    score_by_world_id: Dict[str, Dict[str, float]] = defaultdict(dict)\\n    resets_by_user_id: Dict[str, List[str]] = defaultdict(list)\\n    uncaught_errors: List[BaseException] = []\\n    expected_errors: List[ScoreResult] = []\\n\\n    def on_done(result: ScoreResult):\\n        if result.is_error:\\n            expected_errors.append(result)\\n        elif result.is_reset:\\n            resets_by_user_id[result.user_id].append(result.world_id)\\n        else:\\n            score_by_world_id[result.world_id][result.user_id] = result.score\\n\\n    def on_error(error: BaseException):\\n        logger.error(\\\"Evaluation failed!\\\")\\n        uncaught_errors.append(error)\\n        raise error\\n\\n    num_processes = 20\\n\\n    pool_results = []\\n\\n    config = get_oculus_playback_config(is_using_human_input=False)\\n    action_type = get_action_type_from_config(config)\\n    env = create_env(config, action_type)\\n    selected_features = env.observation_context.selected_features\\n    env.close()\\n\\n    with Pool(processes=num_processes) as worker_pool:\\n        requests = []\\n        for world_path in list(root_path.iterdir()):\\n            world_id = world_path.name\\n            if (\\n                (world_path / \\\"ignored.marker\\\").exists()\\n                or world_id.startswith(\\\"practice\\\")\\n                or world_id.startswith(\\\"worlds\\\")\\n                or world_id.startswith(\\\"versions\\\")\\n            ):\\n                continue\\n            for user_path in world_path.iterdir():\\n                user_id = user_path.name\\n                if (user_path / \\\"crash\\\").exists():\\n                    continue\\n\\n                task_name, seed, difficulty = world_id.split(\\\"__\\\")\\n                cleaned_world_id = f\\\"{task_name}__{int(seed)}__{difficulty}\\\"\\n\\n                request = worker_pool.apply_async(\\n                    get_human_score_from_data,\\n                    kwds={\\n                        \\\"user_path\\\": user_path,\\n                        \\\"world_id\\\": cleaned_world_id,\\n                        \\\"user_id\\\": user_id,\\n                        \\\"selected_features\\\": selected_features,\\n                    },\\n                    callback=on_done,\\n                    error_callback=on_error,\\n                )\\n                requests.append(request)\\n        for request in tqdm(requests):\\n            request.wait()\\n            if request._success:\\n                pool_results.append(request.get())\\n        worker_pool.close()\\n        worker_pool.join()\\n\\n    return HumanScores(\\n        score_by_world_id,\\n        resets_by_user_id,\\n        uncaught_errors,\\n        expected_errors,\\n    )\\n\\n\\n# %%\\n\\nAVALON_BUCKET_NAME = \\\"avalon-benchmark\\\"\\ns3_client = SimpleS3Client(bucket_name=AVALON_BUCKET_NAME)\\n\\ntmp_path = Path(f\\\"{FILESYSTEM_ROOT}/tmp/\\\")\\nkey = \\\"avalon_human_data__0908.tar.gz\\\"\\ntar_path = tmp_path / key\\ns3_client.download_to_file(key=key, output_path=tar_path)\\n\\n# %%\\n\\nroot_path = tmp_path / \\\"avalon_human_data\\\"\\ntar = tarfile.open(tar_path)\\ntar.extractall(path=root_path.parent)\\ntar.close()\\ntar_path.unlink()\\n\\n# %%\\n\\nresults = get_all_human_scores(root_path)\\n\\n# %%\\n\\njson.dump(results.score_by_world_id, open(tmp_path / \\\"human_scores.json\\\", \\\"w\\\"))\\n\"}}, \"id\": 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPYTHON: Registering Comms\n",
      "==> Success\n",
      "Timed out waiting for syncing to complete.\n",
      "Got Response:\n",
      "\t\t{\"jsonrpc\": \"2.0\", \"result\": \"Syncing all cells\", \"id\": 1}\n",
      "('POST / HTTP/1.1', '200', '-')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavalon_human_data__0908.tar.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m tar_path \u001b[38;5;241m=\u001b[39m tmp_path \u001b[38;5;241m/\u001b[39m key\n\u001b[0;32m----> 7\u001b[0m \u001b[43ms3_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtar_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/projects/avalon/avalon/contrib/s3_utils.py:62\u001b[0m, in \u001b[0;36mSimpleS3Client.download_to_file\u001b[0;34m(self, key, output_path)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_to_file\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m, output_path: Path):\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbucket_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabsolute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.9/site-packages/boto3/s3/inject.py:190\u001b[0m, in \u001b[0;36mdownload_file\u001b[0;34m(self, Bucket, Key, Filename, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m\"\"\"Download an S3 object to a file.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03mUsage::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m    transfer.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m S3Transfer(\u001b[38;5;28mself\u001b[39m, Config) \u001b[38;5;28;01mas\u001b[39;00m transfer:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransfer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mKey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mExtraArgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.9/site-packages/boto3/s3/transfer.py:320\u001b[0m, in \u001b[0;36mS3Transfer.download_file\u001b[0;34m(self, bucket, key, filename, extra_args, callback)\u001b[0m\n\u001b[1;32m    316\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39mdownload(\n\u001b[1;32m    317\u001b[0m     bucket, key, filename, extra_args, subscribers\n\u001b[1;32m    318\u001b[0m )\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# This is for backwards compatibility where when retries are\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;66;03m# exceeded we need to throw the same error from boto3 instead of\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# s3transfer's built in RetriesExceededError as current users are\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;66;03m# catching the boto3 one instead of the s3transfer exception to do\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# their own retries.\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m S3TransferRetriesExceededError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/venv/lib/python3.9/site-packages/s3transfer/futures.py:106\u001b[0m, in \u001b[0;36mTransferFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[0;32m--> 106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/opt/venv/lib/python3.9/site-packages/s3transfer/futures.py:103\u001b[0m, in \u001b[0;36mTransferFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;66;03m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;66;03m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;66;03m# out of this and propagate the exception.\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_coordinator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m/opt/venv/lib/python3.9/site-packages/s3transfer/futures.py:261\u001b[0m, in \u001b[0;36mTransferCoordinator.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;124;03m\"\"\"Waits until TransferFuture is done and returns the result\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \n\u001b[1;32m    253\u001b[0m \u001b[38;5;124;03mIf the TransferFuture succeeded, it will return the result. If the\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03mTransferFuture failed, it will raise the exception associated to the\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;124;03mfailure.\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# Doing a wait() with no timeout cannot be interrupted in python2 but\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# can be interrupted in python3 so we just wait with the largest\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# possible value integer value, which is on the scale of billions of\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# years...\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_done_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMAXINT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# Once done waiting, raise an exception if present or return the\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# final result.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n",
      "File \u001b[0;32m/usr/lib/python3.9/threading.py:574\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    572\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 574\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "AVALON_BUCKET_NAME = \"avalon-benchmark\"\n",
    "s3_client = SimpleS3Client(bucket_name=AVALON_BUCKET_NAME)\n",
    "\n",
    "tmp_path = Path(f\"{FILESYSTEM_ROOT}/tmp/\")\n",
    "key = \"avalon_human_data__0908.tar.gz\"\n",
    "tar_path = tmp_path / key\n",
    "s3_client.download_to_file(key=key, output_path=tar_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root_path = tmp_path / \"avalon_human_data\"\n",
    "tar = tarfile.open(tar_path)\n",
    "tar.extractall(path=root_path.parent)\n",
    "tar.close()\n",
    "tar_path.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = get_all_human_scores(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json.dump(results.score_by_world_id, open(tmp_path / \"human_scores.json\", \"w\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
